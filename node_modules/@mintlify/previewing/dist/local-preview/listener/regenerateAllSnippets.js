import { findAndRemoveImports, replaceVariables, stringifyTree, topologicalSort, hasImports, optionallyAddLeadingSlash, optionallyRemoveLeadingSlash, resolveImportPath, resolveAllImports as baseResolveAllImports, isSnippetExtension, isImportedAsSnippet, } from '@mintlify/common';
import { preparseMdxTree, getFileListSync, getFileExtension } from '@mintlify/prebuild';
import { outputFile } from 'fs-extra';
import { readFile } from 'fs/promises';
import { join } from 'path';
import { CMD_EXEC_PATH, NEXT_PUBLIC_PATH } from '../../constants.js';
import { getImportedFilesFromCache } from './importCache.js';
import { getCurrentVariables, handleParseError } from './utils.js';
const getV2SnippetFilenames = () => {
    const importedFiles = getImportedFilesFromCache();
    return getFileListSync(CMD_EXEC_PATH).filter((file) => {
        if (!isSnippetExtension(getFileExtension(file)))
            return false;
        if (file.startsWith('snippets/'))
            return true;
        if (getFileExtension(file) === 'jsx')
            return true;
        return isImportedAsSnippet(file, importedFiles);
    });
};
export const regenerateAllSnippets = async () => {
    const variables = await getCurrentVariables();
    const vars = variables ?? {};
    const snippetFilenames = getV2SnippetFilenames();
    const processedSnippets = [];
    const resolvedTrees = [];
    const v2Parsed = [];
    for (const filename of snippetFilenames) {
        try {
            const targetFilename = optionallyRemoveLeadingSlash(filename);
            const rawContent = await readFile(join(CMD_EXEC_PATH, targetFilename), 'utf8');
            const content = replaceVariables(rawContent, vars);
            const tree = await preparseMdxTree(content, CMD_EXEC_PATH, join(CMD_EXEC_PATH, targetFilename), handleParseError);
            const normalizedFilename = optionallyAddLeadingSlash(filename);
            const processed = await findAndRemoveImports(tree);
            v2Parsed.push({
                filename: normalizedFilename,
                content,
                importData: { filename: normalizedFilename, ...processed },
            });
        }
        catch (err) {
            console.warn(`Failed to parse snippet ${filename}:`, err);
        }
    }
    const graph = {};
    for (const { importData } of v2Parsed) {
        graph[importData.filename] = Object.keys(importData.importMap)
            .map((dep) => resolveImportPath(dep, importData.filename))
            .filter((resolvedDep) => resolvedDep != null);
    }
    const sortedFilenames = topologicalSort(graph).reverse();
    const v2Map = new Map(v2Parsed.map((item) => [item.filename, item]));
    const orderedV2 = sortedFilenames
        .map((filename) => v2Map.get(filename))
        .filter((item) => item != null);
    for (const { filename, content, importData } of orderedV2) {
        try {
            const targetFilename = optionallyRemoveLeadingSlash(filename);
            if (!hasImports(importData)) {
                await outputFile(join(NEXT_PUBLIC_PATH, targetFilename), content, { flag: 'w' });
                resolvedTrees.push({ filename, tree: importData.tree });
            }
            else {
                const resolvedTree = await baseResolveAllImports({
                    snippets: resolvedTrees,
                    fileWithImports: importData,
                });
                await outputFile(join(NEXT_PUBLIC_PATH, targetFilename), stringifyTree(resolvedTree), {
                    flag: 'w',
                });
                resolvedTrees.push({ filename, tree: resolvedTree });
            }
            processedSnippets.push(targetFilename);
        }
        catch (err) {
            console.warn(`Failed to regenerate snippet ${filename}:`, err);
        }
    }
    return processedSnippets;
};
